{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63d05d5-672d-45f6-bf90-0943c3b44b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
      "    Python  3.10.13 (you have 3.10.12)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from audiocraft.modules.conditioners import JointEmbedCondition, SegmentWithAttributes, WavCondition, ConditioningAttributes\n",
    "from config import Config\n",
    "from audiomodel import AudioProcessing\n",
    "from audiodataset_seperation import SeperationDataset, TestDataset\n",
    "\n",
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def wandb_init(cfg):\n",
    "    wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=cfg.wandb_project_name,\n",
    "            \n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": cfg.learning_rate,\n",
    "            \"epochs\": cfg.num_train_epochs,\n",
    "            \"batch_size\": cfg.batch_size,\n",
    "            }\n",
    "    )\n",
    "    \n",
    "def save_checkpoint(cfg, model, result, best_loss, epoch=0):\n",
    "    save_checkpoint = False\n",
    "    with open(\"{}/summary.jsonl\".format(cfg.output_dir), \"a\") as f:\n",
    "        f.write(json.dumps(result) + \"\\n\\n\")\n",
    "        \n",
    "    if result[\"valid_loss\"] < best_loss:\n",
    "      best_loss = result[\"valid_loss\"]\n",
    "      save_checkpoint = True\n",
    "      \n",
    "    # 모델 상태 저장\n",
    "    if save_checkpoint and cfg.checkpointing_steps == \"best\":\n",
    "        torch.save(model.state_dict(), os.path.join(cfg.output_dir, f\"best.pth\"))\n",
    "\n",
    "    #torch.save(model.state_dict(), os.path.join(cfg.output_dir, \"last.pth\"))\n",
    "    torch.save(model.state_dict(), os.path.join(cfg.output_dir, f\"{epoch}.pth\"))\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c470cb93-e060-46d3-bfc5-7efaa6140634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg):\n",
    "        from audiocraft.models.loaders import load_compression_model, load_lm_model\n",
    "        \"\"\"Instantiate models and optimizer.\"\"\"     \n",
    "        compression_model = load_compression_model('facebook/audiogen-medium', device=cfg.device)\n",
    "        lm = load_lm_model('facebook/audiogen-medium', device=cfg.device)\n",
    "        return compression_model, lm\n",
    "\n",
    "def process_audio_tokenizer(wav, compression_model):\n",
    "    \"\"\"\n",
    "    Get wav audio and return audio tokens\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        audio_tokens, scale = compression_model.encode(wav)\n",
    "    return audio_tokens\n",
    "\n",
    "def post_process_audio_tokenizer(audio_tokens, audio_lengths=None, compression_model=None, lm=None, cfg=None):\n",
    "    \"\"\"\n",
    "    For Masking\n",
    "    \"\"\"\n",
    "    padding_mask = torch.ones_like(audio_tokens, dtype=torch.bool, device=audio_tokens.device)\n",
    "    audio_tokens = audio_tokens.clone()\n",
    "    padding_mask = padding_mask.clone()\n",
    "    token_sample_rate = compression_model.frame_rate\n",
    "    # B : batch size\n",
    "    # K : codebook num\n",
    "    # T_s : duration * 50(임의 지정, encodec's frame rate)\n",
    "    B, K, T_s = audio_tokens.shape\n",
    "    \n",
    "    for i in range(B):\n",
    "        valid_tokens = math.floor(audio_lengths[i] / cfg.sample_rate * token_sample_rate)\n",
    "        audio_tokens[i, :, valid_tokens:] = lm.special_token_id # 2048이다.\n",
    "        padding_mask[i, :, valid_tokens:] = 0\n",
    "\n",
    "    return audio_tokens, padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f6dca3-cfeb-464e-ba1b-9d940db48b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "  0%|          | 0/41210000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "base_path = \"./csv_files/\"\n",
    "train_data_path = f\"{base_path}/train_dataset_epidemic_sub.csv\"\n",
    "eval_data_path = f\"{base_path}/eval_dataset_epidemic_sub.csv\"\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "cfg.update(train_data_path=train_data_path, eval_data_path=eval_data_path, batch_size=1)\n",
    "\n",
    "accelerator = Accelerator(gradient_accumulation_steps=cfg.gradient_accumulation_steps)\n",
    "cfg.update(device=accelerator.device)\n",
    "make_dir(cfg.output_dir)\n",
    "make_dir(cfg.generated_dir)\n",
    "# if accelerator.is_main_process: \n",
    "#     wandb_init(cfg)\n",
    "\n",
    "with accelerator.main_process_first():  \n",
    "    compression_model, lm = build_model(cfg)\n",
    "    audio_dataset = SeperationDataset(cfg, train=True)\n",
    "    eval_dataset = SeperationDataset(cfg, train=False)\n",
    "compression_model.eval()\n",
    "\n",
    "model = AudioProcessing(cfg, lm)\n",
    "test_dataset = TestDataset(cfg)\n",
    "\n",
    "audio_dataloader = DataLoader(audio_dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=8)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=cfg.eval_batch_size, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# gradients for lm\n",
    "optimizer_parameters = [param for param in model.lm.parameters() if param.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_parameters, \n",
    "    lr=cfg.learning_rate,\n",
    "    betas=(cfg.adam_beta1, cfg.adam_beta2),\n",
    "    weight_decay=cfg.adam_weight_decay,\n",
    "    eps=cfg.adam_epsilon,\n",
    ")\n",
    "\n",
    "num_update_steps_per_epoch = math.ceil(len(audio_dataloader) / cfg.gradient_accumulation_steps)\n",
    "if cfg.max_train_steps is None:\n",
    "  cfg.max_train_steps = cfg.num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "      name=cfg.lr_scheduler_type,\n",
    "      optimizer=optimizer,\n",
    "      num_warmup_steps=cfg.num_warmup_steps * cfg.gradient_accumulation_steps,\n",
    "      num_training_steps=cfg.max_train_steps * cfg.gradient_accumulation_steps,\n",
    "  )\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    if cfg.resume_from_checkpoint is not None:\n",
    "        accelerator.print(f\"Resumed from local checkpoint: {cfg.resume_from_checkpoint}\")\n",
    "        model.load_state_dict(torch.load(cfg.resume_from_checkpoint, map_location=accelerator.device))\n",
    "        #accelerator.load_state(cfg.resume_from_checkpoint)\n",
    "\n",
    "\n",
    "audio_dataloader, eval_dataloader, model, compression_model, optimizer, lr_scheduler = accelerator.prepare(\n",
    "    audio_dataloader, eval_dataloader, model, compression_model, optimizer, lr_scheduler\n",
    ")\n",
    "\n",
    "starting_epoch, completed_steps, best_loss, save_epoch = 0, 0, np.inf, 0\n",
    "progress_bar = tqdm(range(cfg.max_train_steps), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30495eae-98a5-4c0e-af05-1998790addd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.815986394557823\n",
      "torch.Size([1, 4, 141])\n",
      "torch.Size([1, 4, 141])\n",
      "torch.Size([1, 4, 141])\n"
     ]
    }
   ],
   "source": [
    "from audiotools import AudioSignal\n",
    "wav_path = \"0rMqlwSi9u.wav\"\n",
    "\n",
    "wav = AudioSignal(wav_path)\n",
    "sl = wav.signal_length\n",
    "print(wav.duration)\n",
    "\n",
    "wav.to_mono()\n",
    "wav.resample(16000)\n",
    "wav.truncate_samples(48000)\n",
    "\n",
    "# torch.tensor(wav.numpy())\n",
    "\n",
    "unwrapped_vae = accelerator.unwrap_model(compression_model)\n",
    "\n",
    "audio_tokens = process_audio_tokenizer(torch.tensor(wav.numpy()).to(accelerator.device), unwrapped_vae)\n",
    "\n",
    "print(audio_tokens.shape)\n",
    "\n",
    "audio_tokens2, padding_mask = post_process_audio_tokenizer(audio_tokens, [sl], unwrapped_vae, lm, cfg)\n",
    "print(audio_tokens2.shape)\n",
    "print(padding_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bc3d96-a782-4486-9484-8b8a35d05523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 48000])\n",
      "(\"Remove 'The clear and crisp sound of a door being closed, captured in mono with no background noise. Perfect for use in video games, movies, and tutorials.'\",)\n",
      "torch.Size([1, 1, 48000])\n",
      "tensor([74793], device='cuda:0')\n",
      "torch.Size([1, 4, 150])\n",
      "torch.Size([1, 4, 150])\n",
      "logits :  tensor([[[[-1.9453, -8.3282, -3.4557,  ..., -7.7003, -2.2204, -2.5620],\n",
      "          [-2.1539, -6.8257, -4.4074,  ..., -6.9874, -2.8900, -3.6284],\n",
      "          [-1.9611, -5.7711, -3.5935,  ..., -4.3697, -1.2969, -3.5035],\n",
      "          ...,\n",
      "          [-0.6441, -3.9716, -1.6830,  ..., -2.5556, -1.4842, -1.7736],\n",
      "          [-0.6564, -3.9135, -1.6645,  ..., -2.4994, -1.4727, -1.7453],\n",
      "          [-0.6395, -3.8795, -1.6337,  ..., -2.4380, -1.4316, -1.7322]],\n",
      "\n",
      "         [[-3.9193, -5.1663, -6.0390,  ...,  0.8620, -0.2039, -8.5069],\n",
      "          [-4.0252, -2.4035, -5.9598,  ..., -2.2706, -0.9123, -5.7665],\n",
      "          [-1.5002, -2.4417, -3.9796,  ..., -0.8868, -1.6147, -5.3618],\n",
      "          ...,\n",
      "          [-2.4975, -1.6238, -4.2477,  ..., -0.5687, -1.1187, -4.8636],\n",
      "          [-2.4831, -1.6021, -4.2370,  ..., -0.6276, -1.1586, -4.8722],\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "         [[-1.2918, -5.8363, -6.5517,  ..., -5.4088, -4.3926, -3.0916],\n",
      "          [-1.2607, -5.1379, -5.4987,  ..., -4.7485, -3.5284, -2.5211],\n",
      "          [ 0.1555, -6.2074, -6.9235,  ..., -5.6491, -2.6201, -5.3798],\n",
      "          ...,\n",
      "          [ 1.9836, -4.5584, -5.1301,  ..., -3.9487, -2.2441, -5.3718],\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "         [[-5.1763, -3.8960, -3.9167,  ...,  4.2071, -6.7573,  1.2810],\n",
      "          [-7.8399, -4.6855, -5.2385,  ...,  4.2674, -7.8036,  0.9450],\n",
      "          [-7.0497, -4.7455, -3.8596,  ...,  3.0128, -7.3543,  1.1315],\n",
      "          ...,\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "          [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]]],\n",
      "       device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "model_output :  torch.Size([1, 4, 150])\n"
     ]
    }
   ],
   "source": [
    "synthesized_audio, prompt, ground_truth, length = next(iter(audio_dataloader))\n",
    "\n",
    "print(synthesized_audio.shape)\n",
    "print(prompt)\n",
    "print(ground_truth.shape)\n",
    "print(length)\n",
    "\n",
    "synthesized_audio_tokens = process_audio_tokenizer(synthesized_audio, unwrapped_vae)\n",
    "synthesized_audio_tokens, synthesized_padding_mask = post_process_audio_tokenizer(synthesized_audio_tokens, length, unwrapped_vae, lm, cfg)\n",
    "\n",
    "print(synthesized_audio_tokens.shape)\n",
    "print(synthesized_padding_mask.shape)\n",
    "\n",
    "# for batch_idx, (synthesized_wav, prompts, ground_truth, lengths) in enumerate(audio_dataloader):\n",
    "#     print(batch_idx)\n",
    "#     if batch_idx == 4:\n",
    "#         break\n",
    "\n",
    "\n",
    "attributes = [\n",
    "    ConditioningAttributes(text={'description': str(description)})\n",
    "    for description in prompt\n",
    "]\n",
    "loss, model_output = model(synthesized_audio_tokens, synthesized_padding_mask, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4348d9-adfe-4ed0-991a-02ec5187445a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b48e6b1-3df6-4626-989a-e58ccb7f0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------EPOCH0-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>total_loss, total_val_loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model.train()                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch_idx, (synthesized_wav, prompts, ground_truth, lengths) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(audio_    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Consider batch</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> accelerator.accumulate(model):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">377</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">374 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dataloader_iter = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">375 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># We iterate one batch ahead to check when we are at the end</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">376 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>377 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>current_batch = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(dataloader_iter)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">378 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">379 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">380 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">630</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 629 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 630 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 633 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1345</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1342 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx] += (data,)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx]                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1345 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_data(data)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1346 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_put_index</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prefetch_factor * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_workers        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1371</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_process_data</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._rcvd_idx += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1369 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._try_put_index()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(data, ExceptionWrapper):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1371 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data.reraise()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1372 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1373 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1374 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mark_worker_as_unavailable</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, worker_id, shutdown=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">694</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">691 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If the exception takes multiple arguments, don't try to</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">692 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># instantiate since we don't know how to</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">693 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>694 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exception                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">695 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">696 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">697 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_available_device_type</span>():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>Caught NameError in DataLoader worker process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.\n",
       "Original Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">308</span>, in _worker_loop\n",
       "    data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fetcher.fetch</span><span style=\"font-weight: bold\">(</span>index<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>, in fetch\n",
       "    data = <span style=\"font-weight: bold\">[</span>self.dataset<span style=\"font-weight: bold\">[</span>idx<span style=\"font-weight: bold\">]</span> for idx in possibly_batched_index<span style=\"font-weight: bold\">]</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>, in <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">listcomp</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "    data = <span style=\"font-weight: bold\">[</span>self.dataset<span style=\"font-weight: bold\">[</span>idx<span style=\"font-weight: bold\">]</span> for idx in possibly_batched_index<span style=\"font-weight: bold\">]</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/workspace/audiogen-finetune/audiodataset_seperation.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, in __getitem__\n",
       "    wav = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.process_data</span><span style=\"font-weight: bold\">(</span>wav<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/workspace/audiogen-finetune/audiodataset_seperation.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>, in process_data\n",
       "    zero_wavs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.zeros</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48000</span><span style=\"font-weight: bold\">))</span>\n",
       "NameError: name <span style=\"color: #008000; text-decoration-color: #008000\">'np'</span> is not defined\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mtotal_loss, total_val_loss = \u001b[94m0\u001b[0m, \u001b[94m0\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0mmodel.train()                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m batch_idx, (synthesized_wav, prompts, ground_truth, lengths) \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(audio_    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Consider batch\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m accelerator.accumulate(model):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33mdata_loader.py\u001b[0m:\u001b[94m377\u001b[0m in \u001b[92m__iter__\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m374 \u001b[0m\u001b[2m│   │   \u001b[0mdataloader_iter = \u001b[96msuper\u001b[0m().\u001b[92m__iter__\u001b[0m()                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m375 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We iterate one batch ahead to check when we are at the end\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m376 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m377 \u001b[2m│   │   │   \u001b[0mcurrent_batch = \u001b[96mnext\u001b[0m(dataloader_iter)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m378 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m379 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m380 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m630\u001b[0m in \u001b[92m__next__\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 627 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 628 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 629 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 630 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 632 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 633 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m1345\u001b[0m in \u001b[92m_next_data\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1342 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._task_info[idx] += (data,)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1343 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1344 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mdel\u001b[0m \u001b[96mself\u001b[0m._task_info[idx]                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1345 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._process_data(data)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1346 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1347 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_try_put_index\u001b[0m(\u001b[96mself\u001b[0m):                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1348 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._tasks_outstanding < \u001b[96mself\u001b[0m._prefetch_factor * \u001b[96mself\u001b[0m._num_workers        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m1371\u001b[0m in \u001b[92m_process_data\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._rcvd_idx += \u001b[94m1\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1369 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._try_put_index()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1370 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(data, ExceptionWrapper):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1371 \u001b[2m│   │   │   \u001b[0mdata.reraise()                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1372 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1373 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1374 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_mark_worker_as_unavailable\u001b[0m(\u001b[96mself\u001b[0m, worker_id, shutdown=\u001b[94mFalse\u001b[0m):                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_utils.py\u001b[0m:\u001b[94m694\u001b[0m in \u001b[92mreraise\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m691 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If the exception takes multiple arguments, don't try to\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m692 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# instantiate since we don't know how to\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m693 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m694 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exception                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m695 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m696 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m697 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_available_device_type\u001b[0m():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mCaught NameError in DataLoader worker process \u001b[1;36m0\u001b[0m.\n",
       "Original Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\"\u001b[0m, line \u001b[1;36m308\u001b[0m, in _worker_loop\n",
       "    data = \u001b[1;35mfetcher.fetch\u001b[0m\u001b[1m(\u001b[0mindex\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line \u001b[1;36m51\u001b[0m, in fetch\n",
       "    data = \u001b[1m[\u001b[0mself.dataset\u001b[1m[\u001b[0midx\u001b[1m]\u001b[0m for idx in possibly_batched_index\u001b[1m]\u001b[0m\n",
       "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line \u001b[1;36m51\u001b[0m, in \u001b[1m<\u001b[0m\u001b[1;95mlistcomp\u001b[0m\u001b[1m>\u001b[0m\n",
       "    data = \u001b[1m[\u001b[0mself.dataset\u001b[1m[\u001b[0midx\u001b[1m]\u001b[0m for idx in possibly_batched_index\u001b[1m]\u001b[0m\n",
       "  File \u001b[32m\"/workspace/audiogen-finetune/audiodataset_seperation.py\"\u001b[0m, line \u001b[1;36m50\u001b[0m, in __getitem__\n",
       "    wav = \u001b[1;35mself.process_data\u001b[0m\u001b[1m(\u001b[0mwav\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/workspace/audiogen-finetune/audiodataset_seperation.py\"\u001b[0m, line \u001b[1;36m33\u001b[0m, in process_data\n",
       "    zero_wavs = \u001b[1;35mnp.zeros\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m48000\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "NameError: name \u001b[32m'np'\u001b[0m is not defined\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(starting_epoch, 3):\n",
    "    accelerator.print(f\"-------------------EPOCH{epoch}-------------------------\" )\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (synthesized_wav, prompts, ground_truth, lengths) in enumerate(audio_dataloader):\n",
    "        # Consider batch\n",
    "        with accelerator.accumulate(model):\n",
    "            with torch.no_grad():\n",
    "                unwrapped_vae = accelerator.unwrap_model(compression_model)\n",
    "                synthesized_audio_tokens = process_audio_tokenizer(synthesized_wav, unwrapped_vae)\n",
    "                synthesized_audio_tokens, synthesized_padding_mask = post_process_audio_tokenizer(synthesized_audio_tokens, lengths, unwrapped_vae, lm, cfg)\n",
    "                \n",
    "                audio_tokens = process_audio_tokenizer(wav, unwrapped_vae)\n",
    "                audio_tokens, padding_mask = post_process_audio_tokenizer(audio_tokens, lengths, unwrapped_vae, lm, cfg)\n",
    "                \n",
    "                attributes = [\n",
    "                    ConditioningAttributes(text={'description': str(description)})\n",
    "                    for description in prompts\n",
    "                ]\n",
    "\n",
    "            mask_token_seperation = torch.tensor([[[lm.special_token_id],[lm.special_token_id],[lm.special_token_id],[lm.special_token_id]]]).to(accelerator.device)\n",
    "            mask_padding_token_seperation = torch.ones(mask_token_seperation.shape).to(accelerator.device)\n",
    "            \n",
    "            made_up = torch.concatenate((synthesized_audio_tokens, mask_token_seperation, audio_tokens), dim=2)\n",
    "            made_padding = torch.concatenate((synthesized_padding_mask, mask_padding_token_seperation, padding_mask), dim=2)\n",
    "            print(made_up.shape, made_padding.shape, attributes)\n",
    "            \n",
    "            loss = model(audio_tokens, padding_mask, attributes)\n",
    "            ppl =  torch.exp(loss)\n",
    "            total_loss += loss.detach().float()\n",
    "            accelerator.backward(loss)     \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if accelerator.sync_gradients:\n",
    "                progress_bar.update(1)\n",
    "                completed_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc648cfb-f8f9-4964-b304-52f0ff4e215f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a804d92-2b6f-4393-bf20-9800afc3c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# dff = pd.read_csv(eval_data_path)\n",
    "# import random\n",
    "\n",
    "# randoms = []\n",
    "# for i in range(len(dff)):\n",
    "#     random_integer = random.randint(0, len(dff))\n",
    "#     while random_integer == i:\n",
    "#         random_integer = random.randint(0, len(dff))\n",
    "#     randoms.append(random_integer)\n",
    "\n",
    "# dff['synthesized_index'] = randoms\n",
    "\n",
    "# dff[:10]\n",
    "\n",
    "# dff.to_csv(eval_data_path, index=False)  # 'your_file_modified.csv' will be the new file with the additional column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "680bd2a1-83bc-4b16-9416-fe7a60122546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51729d-b528-44cb-8e0b-65586771b037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
